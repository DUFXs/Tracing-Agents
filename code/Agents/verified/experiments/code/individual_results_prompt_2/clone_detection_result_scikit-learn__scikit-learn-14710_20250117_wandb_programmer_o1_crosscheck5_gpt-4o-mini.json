{
    "instance_id": "scikit-learn__scikit-learn-14710",
    "agent": "20250117_wandb_programmer_o1_crosscheck5",
    "agent_patch": {
        "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py": "index ad6a5a8ca..07d373d66 100644\n     def _check_early_stopping_scorer(self, X_binned_small_train, y_small_train,\n                                      X_binned_val, y_val):\n         \"\"\"Check if fitting should be early-stopped based on scorer.\n\n         Scores are computed on validation data or on training data.\n         \"\"\"\n# If in classification context, decode y to original labels so that\n# y matches predict() which returns string labels.\nif hasattr(self, 'classes_'):\ny_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n\n         if self._use_validation_data:\nif hasattr(self, 'classes_'):\ny_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\n             )\n             return self._should_stop(self.validation_score_)\n         else:\n             return self._should_stop(self.train_score_)\n\n \n     def _check_early_stopping_loss(self,\n                                    raw_predictions,\n",
        "test_early_stopping_string_target.py": "new file mode 100644\nindex 000000000..de52bc17e\nimport sys\nimport numpy as np\nimport traceback\n\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nimport warnings\n\ndef main():\nprint(\"Starting test to check bug with string target and early stopping in HistGradientBoostingClassifier.\")\nrng = np.random.RandomState(0)\nX = rng.randn(100, 10)\ny = np.array(['x'] * 50 + ['y'] * 50, dtype=object)\ntry:\nprint(\"Creating HistGradientBoostingClassifier with n_iter_no_change=5, max_iter=10\")\ngbrt = HistGradientBoostingClassifier(n_iter_no_change=5, max_iter=10)\nprint(\"Fitting model with string target y:\", y)\ngbrt.fit(X, y)\nprint(\"Model was successfully fit. Checking predictions.\")\npreds = gbrt.predict(X)\nprint(\"preds:\", preds)\nif preds.shape != (100,):\nprint(\"Unexpected shape of predictions:\", preds.shape)\nsys.exit(1)\nwith warnings.catch_warnings():\nwarnings.filterwarnings(\"ignore\")\nscore = gbrt.score(X, y)\nprint(\"score:\", score)\nif score < 0.4:\nprint(\"Score is suspiciously low. Possibly the model isn't working right:\", score)\nsys.exit(1)\nprint(\"Test passed!\")\nsys.exit(0)\nexcept Exception as e:\ntraceback.print_exc()\nprint(\"A failure was raised, so the test fails.\")\nsys.exit(1)\n\nif __name__ == \"__main__\":\nmain()\n"
    },
    "ground_truth_patch": {
        "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py": " \n         Scores are computed on validation data or on training data.\n         \"\"\"\nif is_classifier(self):\ny_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n \n         if self._use_validation_data:\nif is_classifier(self):\ny_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\n             )\n"
    },
    "response": "{\"explanation\": \"The code in code sample 1 defines a function to check whether training should be early-stopped based on the performance of a scorer applied to training and validation datasets in a machine learning context. It handles the conversion of label indices to original classes for classification purposes and tracks the scores during training. The function attempts to ensure the model is validated appropriately on both training and validation datasets. On the other hand, code sample 2 appears to be a part of the same function and is focused on recording validation scores, but it uses a different function, `is_classifier`, to determine if the context is classification instead of checking the presence of `classes_`. This change modifies the control flow for handling the scorer for the training dataset. Thus, while related, they differ in implementation details.\", \"is_clone\": true, \"classification\": \"type-3\", \"reasoning\": \"These code samples are type-3 clones because they are syntactically similar but contain added or modified components; specifically, sample 2 modifies how the check for the context of classification is performed, which alters the flow of execution.\"}"
}