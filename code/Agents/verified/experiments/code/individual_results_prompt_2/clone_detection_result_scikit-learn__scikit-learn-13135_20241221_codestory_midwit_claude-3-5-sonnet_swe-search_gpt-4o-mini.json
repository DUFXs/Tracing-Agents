{
    "instance_id": "scikit-learn__scikit-learn-13135",
    "agent": "20241221_codestory_midwit_claude-3-5-sonnet_swe-search",
    "agent_patch": {
        "edge_cases.py": "new file mode 100644\nindex 000000000..4832f7217\nimport numpy as np\nfrom sklearn.preprocessing import KBinsDiscretizer\n\n# Test case 1: Original case\nX1 = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)\nest1 = KBinsDiscretizer(n_bins=5, strategy='kmeans', encode='ordinal')\nXt1 = est1.fit_transform(X1)\nprint(\"Test case 1 (original):\")\nprint(Xt1)\n\n# Test case 2: Reversed data\nX2 = np.array([10, 9, 3, 2, 0.5, 0]).reshape(-1, 1)\nest2 = KBinsDiscretizer(n_bins=5, strategy='kmeans', encode='ordinal')\nXt2 = est2.fit_transform(X2)\nprint(\"\\nTest case 2 (reversed data):\")\nprint(Xt2)\n\n# Test case 3: More extreme case with repeated values\nX3 = np.array([0, 0, 1, 1, 10, 10, 100, 100]).reshape(-1, 1)\nest3 = KBinsDiscretizer(n_bins=4, strategy='kmeans', encode='ordinal')\nXt3 = est3.fit_transform(X3)\nprint(\"\\nTest case 3 (repeated values):\")\nprint(Xt3)\n\n# Test case 4: Single unique value repeated\nX4 = np.array([5, 5, 5, 5]).reshape(-1, 1)\nest4 = KBinsDiscretizer(n_bins=3, strategy='kmeans', encode='ordinal')\nXt4 = est4.fit_transform(X4)\nprint(\"\\nTest case 4 (single value):\")\nprint(Xt4)\n\\ No newline at end of file\n",
        "reproduce_error.py": "new file mode 100644\nindex 000000000..172305e78\nimport numpy as np\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nX = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)\n\n# with 5 bins\nest = KBinsDiscretizer(n_bins=5, strategy='kmeans', encode='ordinal')\nXt = est.fit_transform(X)\nprint(Xt)\n\\ No newline at end of file\n",
        "sklearn/preprocessing/_discretization.py": "index dd969c12b..f25cb3efd 100644\n                 # 1D k-means procedure\n                 km = KMeans(n_clusters=n_bins[jj], init=init, n_init=1)\n                 centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n# Sort centers to ensure bin edges are monotonic\ncenters.sort()\n                 bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5\n                 bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]\n \n"
    },
    "ground_truth_patch": {
        "sklearn/preprocessing/_discretization.py": "                 # 1D k-means procedure\n                 km = KMeans(n_clusters=n_bins[jj], init=init, n_init=1)\n                 centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n# Must sort, centers may be unsorted even with sorted init\ncenters.sort()\n                 bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5\n                 bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]\n \n"
    },
    "response": "{\"explanation\": \"The code in code sample 1 implements several test cases for the KBinsDiscretizer from sklearn to demonstrate how it handles different types of input data. It tests various scenarios including an original data set, reversed data, data with repeated values, and a data set with a single unique value repeated. Each test case applies the discretizer and prints the resulting transformed data. Meanwhile, the code in code sample 2 initializes a KBinsDiscretizer, sets up a single data array, and applies the discretizer to it, printing the result. The second sample lacks the multiple test cases and focuses only on one instance of data transformation.\", \"is_clone\": false, \"classification\": \"N/A\", \"reasoning\": \"These code samples are not clones because they serve different purposes and have different implementations, with the first one handling multiple test cases while the second one only processes a single test case.\"}"
}