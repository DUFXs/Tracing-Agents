{
    "instance_id": "scikit-learn__scikit-learn-15100",
    "agent": "20250117_wandb_programmer_o1_crosscheck5",
    "agent_patch": {
        "check_strip_unicode_issue_repro.py": "new file mode 100644\nindex 000000000..cdfab864a\nimport sys\nfrom sklearn.feature_extraction.text import strip_accents_unicode\n\ndef safe_hex(ch):\nreturn \"0x\" + format(ord(ch), \"04x\")\n\ndef safe_hex_str(s):\nreturn \" \".join(safe_hex(ch) for ch in s)\n\ndef main():\nprint(\"*** Step 1: Reproduce bug ***\")\ns1 = chr(241)  # LATIN SMALL LETTER N WITH TILDE\ns2 = chr(110) + chr(771)  # 'n' + COMBINING TILDE\nprint(\"s1 codepoints:\", [ord(x) for x in s1], \"s1 hex:\", safe_hex_str(s1))\nprint(\"s2 codepoints:\", [ord(x) for x in s2], \"s2 hex:\", safe_hex_str(s2))\nr1 = strip_accents_unicode(s1)\nr2 = strip_accents_unicode(s2)\nprint(\"r1 =>\", safe_hex_str(r1), [ord(x) for x in r1])\nprint(\"r2 =>\", safe_hex_str(r2), [ord(x) for x in r2])\nif r1 == \"n\" and r2 == \"n\":\nprint(\"*** Test passes: problem is fixed ***\")\nsys.exit(0)\nelse:\nprint(\"*** Test fails: problem is present ***\")\nsys.exit(1)\n\nif __name__ == \"__main__\":\nmain()\n",
        "sklearn/feature_extraction/text.py": "index bb5a9d646..6256ef0c4 100644\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n# Always remove combining chars, even if normalized == s\nreturn ''.join([c for c in normalized if not unicodedata.combining(c)])\n\n \n \n def strip_accents_ascii(s):\n"
    },
    "ground_truth_patch": {
        "sklearn/feature_extraction/text.py": "         Remove accentuated char for any unicode symbol that has a direct\n         ASCII equivalent.\n     \"\"\"\ntry:\n# If `s` is ASCII-compatible, then it does not contain any accented\n# characters and we can avoid an expensive list comprehension\ns.encode(\"ASCII\", errors=\"strict\")\n         return s\nexcept UnicodeEncodeError:\nnormalized = unicodedata.normalize('NFKD', s)\n         return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n"
    },
    "response": "{\"explanation\": \"The code in code sample 1 defines functions to handle Unicode characters, specifically reproducing an issue with accent stripping from strings using the 'strip_accents_unicode' function from sklearn. It checks if the stripped versions of two Unicode strings are equivalent and prints the result. The code in code sample 2 appears to be a fragment of the 'strip_accents_ascii' function, which removes accents from Unicode characters that can be represented in ASCII. It normalizes the input string and utilizes a list comprehension to filter out combining characters. \", \"is_clone\": false, \"classification\": \"N/A\", \"reasoning\": \"These code samples are not clones because they serve different functions and implement different logic. Code sample 1 is focused on testing a specific Unicode issue with a function, while code sample 2 is about accent stripping from Unicode symbols.\"}"
}