{
    "instance_id": "scikit-learn__scikit-learn-25931",
    "agent": "20250110_learn_by_interact_claude3.5",
    "agent_patch": {
        "reproduce.py": "new file mode 100644\nindex 000000000..bd19934dd\nfrom sklearn.ensemble import IsolationForest\nimport pandas as pd\nimport numpy as np\n\n# Test case 1: Original case\nX1 = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\nclf1 = IsolationForest(random_state=0, contamination=0.05).fit(X1)\n\n# Test case 2: Multiple numeric features\nX2 = pd.DataFrame({\n\"float\": [-1.1, 0.3, 0.5, 100],\n\"int\": [1, 2, 3, 4],\n\"int64\": pd.Series([1, 2, 3, 4], dtype=\"Int64\")  # pandas nullable integer\n})\nclf2 = IsolationForest(random_state=0, contamination=0.25).fit(X2)\n\n# Test case 3: contamination=\"auto\"\nX3 = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\nclf3 = IsolationForest(random_state=0, contamination=\"auto\").fit(X3)\n\nprint(\"All test cases completed without warnings!\")\n\n",
        "sklearn/ensemble/_iforest.py": "index 4d6c1c3f0..88c607093 100644\n             Fitted estimator.\n         \"\"\"\n         self._validate_params()\n# Store original input for offset computation when contamination != \"auto\"\nself._fit_X = X\n         X = self._validate_data(X, accept_sparse=[\"csc\"], dtype=tree_dtype)\n         if issparse(X):\n             # Pre-sort indices to avoid that each individual tree of the\n             self.offset_ = -0.5\n             return self\n \n# else, define offset_ wrt contamination parameter using original input\nself.offset_ = np.percentile(self.score_samples(self._fit_X), 100.0 * self.contamination)\ndel self._fit_X  # Remove reference to input data\n         return self\n \n\n     def predict(self, X):\n         \"\"\"\n         Predict if a particular sample is an outlier or not.\n     )\n \n     return average_path_length.reshape(n_samples_leaf_shape)\n\n"
    },
    "ground_truth_patch": {
        "sklearn/ensemble/_iforest.py": "             self.offset_ = -0.5\n             return self\n \n# Else, define offset_ wrt contamination parameter\n# To avoid performing input validation a second time we call\n# _score_samples rather than score_samples\nself.offset_ = np.percentile(self._score_samples(X), 100.0 * self.contamination)\n \n         return self\n \n             The anomaly score of the input samples.\n             The lower, the more abnormal.\n         \"\"\"\n         # Check data\n         X = self._validate_data(X, accept_sparse=\"csr\", dtype=np.float32, reset=False)\n \nreturn self._score_samples(X)\n\ndef _score_samples(self, X):\n\"\"\"Private version of score_samples without input validation.\n\nInput validation would remove feature names, so we disable it.\n\"\"\"\n# Code structure from ForestClassifier/predict_proba\n\ncheck_is_fitted(self)\n\n# Take the opposite of the scores as bigger is better (here less abnormal)\n         return -self._compute_chunked_score_samples(X)\n \n     def _compute_chunked_score_samples(self, X):\n"
    },
    "response": "{\"explanation\": \"The code in code sample 1 demonstrates the use of the Isolation Forest model from the sklearn library to detect anomalies in different datasets. It creates several test cases with variations in the data and applies the model with differing parameters for contamination. Meanwhile, the code in code sample 2 appears to be part of the internal implementation of the Isolation Forest algorithm, focusing on the handling of contamination parameters and the prediction of outlier scores. It includes functions for validating data and computing anomaly scores. \", \"is_clone\": false, \"classification\": \"N/A\", \"reasoning\": \"These code samples are not clones because they serve entirely different purposes within the sklearn library. The first sample is user-facing code that demonstrates how to use the Isolation Forest model, while the second sample is an internal function related to the model's implementation. They are not syntactically similar enough to be classified as clones.\"}"
}