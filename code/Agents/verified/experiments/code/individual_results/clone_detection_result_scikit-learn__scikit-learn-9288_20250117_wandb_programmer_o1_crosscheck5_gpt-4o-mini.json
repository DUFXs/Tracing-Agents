{
    "instance_id": "scikit-learn__scikit-learn-9288",
    "agent": "20250117_wandb_programmer_o1_crosscheck5",
    "agent_patch": {
        "sklearn/cluster/k_means_.py": "index b7fbdf7da..7e5e195e8 100644\n     \"\"\"K-means clustering algorithm.\n \n     Read more in the :ref:`User Guide <k_means>`.\n     \"\"\"\n     if n_init <= 0:\n         raise ValueError(\"Invalid number of initializations.\"\n     else:\n         raise ValueError(\"Algorithm must be 'auto', 'full' or 'elkan', got\"\n                          \" %s\" % str(algorithm))\n\n# We unify seed generation so single-thread vs multi-thread\n# uses the exact same set of seeds:\nseeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n\n     if effective_n_jobs(n_jobs) == 1:\n# Single-thread: run k-means once per seed, in series\nfor seed in seeds:\n             labels, inertia, centers, n_iter_ = kmeans_single(\n                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,\n                 verbose=verbose, precompute_distances=precompute_distances,\n                 tol=tol, x_squared_norms=x_squared_norms,\nrandom_state=seed)\n             # determine if these results are the best so far\n             if best_inertia is None or inertia < best_inertia:\n                 best_labels = labels.copy()\n                 best_n_iter = n_iter_\n     else:\n         # parallelisation of k-means runs\n         results = Parallel(n_jobs=n_jobs, verbose=0)(\n             delayed(kmeans_single)(X, sample_weight, n_clusters,\n                                    max_iter=max_iter, init=init,\n                                    verbose=verbose, tol=tol,\n                                    precompute_distances=precompute_distances,\n                                    x_squared_norms=x_squared_norms,\n# pass each seed\n                                    random_state=seed)\n             for seed in seeds)\n         # Get results with the lowest inertia\n         return best_centers, best_labels, best_inertia\n \n \n\n def _kmeans_single_elkan(X, sample_weight, n_clusters, max_iter=300,\n                          init='k-means++', verbose=False, x_squared_norms=None,\n                          random_state=None, tol=1e-4,\n",
        "test_kmeans_njobs_diff.py": "new file mode 100644\nindex 000000000..a6b29250b\n#!/usr/bin/env python\n\nimport sys\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\n\ndef main():\nprint(\"Creating test data...\")\nX, _ = make_blobs(n_samples=10000, centers=10, n_features=2, random_state=2)\n\n# We'll track the inertia values for each n_jobs\ninertias = {}\nfor nj in [1, 2, 3, 4]:\nprint(f\"Running KMeans with n_jobs={nj} ...\")\nkm = KMeans(n_clusters=10, random_state=2, n_jobs=nj)\nkm.fit(X)\ninertias[nj] = km.inertia_\nprint(f\"kmeans.inertia_ = {km.inertia_}\")\n\n# Check if all inertias are the same within a small tolerance\nvalues = list(inertias.values())\ndiff = max(values) - min(values)\n\n# If the difference is bigger than a tiny threshold, we exit nonzero to indicate failure\ntolerance = 1e-7\nprint(f\"\\nInertia values: {inertias}\")\nprint(f\"Difference between max and min inertia: {diff}\")\n\nif diff > tolerance:\nprint(f\"Test failed: KMeans inertia differs across n_jobs by more than {tolerance}\")\nsys.exit(1)\nelse:\nprint(\"Test passed: KMeans inertia is consistent across n_jobs (difference <= tolerance).\")\nsys.exit(0)\n\nif __name__ == \"__main__\":\nmain()\n"
    },
    "ground_truth_patch": {
        "sklearn/cluster/k_means_.py": "     else:\n         raise ValueError(\"Algorithm must be 'auto', 'full' or 'elkan', got\"\n                          \" %s\" % str(algorithm))\n\nseeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n     if effective_n_jobs(n_jobs) == 1:\n         # For a single thread, less memory is needed if we just store one set\n         # of the best results (as opposed to one set per run per thread).\nfor seed in seeds:\n             # run a k-means once\n             labels, inertia, centers, n_iter_ = kmeans_single(\n                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,\n                 verbose=verbose, precompute_distances=precompute_distances,\n                 tol=tol, x_squared_norms=x_squared_norms,\nrandom_state=seed)\n             # determine if these results are the best so far\n             if best_inertia is None or inertia < best_inertia:\n                 best_labels = labels.copy()\n                 best_n_iter = n_iter_\n     else:\n         # parallelisation of k-means runs\n         results = Parallel(n_jobs=n_jobs, verbose=0)(\n             delayed(kmeans_single)(X, sample_weight, n_clusters,\n                                    max_iter=max_iter, init=init,\n"
    },
    "response": "{\"is_clone\": true, \"classification\": \"type-3\", \"reasoning\": \"These code samples are type-3 clones because they share a significant amount of syntax but have additional comments, modifications, and the structure of some statements have been changed, indicating a level of variation that does not make them directly identical or merely differing by identifiers or whitespace.\"}"
}