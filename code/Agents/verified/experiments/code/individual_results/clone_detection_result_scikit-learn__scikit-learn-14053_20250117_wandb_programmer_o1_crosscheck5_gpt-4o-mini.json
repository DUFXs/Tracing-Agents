{
    "instance_id": "scikit-learn__scikit-learn-14053",
    "agent": "20250117_wandb_programmer_o1_crosscheck5",
    "agent_patch": {
        "sklearn/tree/export.py": "index 1fe11e596..07b535320 100644\n     return max(depths)\n \n \ndef export_text(decision_tree, feature_names=None, max_depth=10, spacing=3, decimals=2, show_weights=False):\nfrom ..utils.validation import check_is_fitted\nfrom ..tree import _tree, DecisionTreeClassifier\n \n     check_is_fitted(decision_tree, 'tree_')\n     tree_ = decision_tree.tree_\n     class_names = decision_tree.classes_\n     if max_depth < 0:\n         raise ValueError(\"max_depth bust be >= 0, given %d\" % max_depth)\n \nif (feature_names is not None and len(feature_names) != tree_.n_features):\nraise ValueError(\"feature_names must contain %d elements, got %d\" % (\ntree_.n_features, len(feature_names)))\n \n     if spacing <= 0:\n         raise ValueError(\"spacing must be > 0, given %d\" % spacing)\n     else:\n         value_fmt = \"{}{} value: {}\\n\"\n \n# Fix: map -2 (_tree.TREE_UNDEFINED) to None so we never attempt invalid indexing\n     if feature_names:\nfeature_names_ = [feature_names[i] if i != _tree.TREE_UNDEFINED else None for i in tree_.feature]\n     else:\nfeature_names_ = [\"feature_{}\".format(i) if i != _tree.TREE_UNDEFINED else None for i in tree_.feature]\n \n     export_text.report = \"\"\n \n     def _add_leaf(value, class_name, indent):\n         val = ''\nis_classification = isinstance(decision_tree, DecisionTreeClassifier)\n         if show_weights or not is_classification:\nval_list = [\"{:.{}f}, \".format(v, decimals) for v in value]\nval = '[' + ''.join(val_list)[:-2] + ']'\n         if is_classification:\n             val += ' class: ' + str(class_name)\n         export_text.report += value_fmt.format(indent, '', val)\n         indent = (\"|\" + (\" \" * spacing)) * depth\n         indent = indent[:-spacing] + \"-\" * spacing\n \n         if tree_.n_outputs == 1:\n             value = tree_.value[node][0]\n         else:\n             value = tree_.value[node].T[0]\nclass_name_ = int(value.argmax())\nif tree_.n_classes[0] != 1 and tree_.n_outputs == 1:\nc = class_names[class_name_]\nelse:\nc = class_name_\n \nif depth <= max_depth + 1:\n             if tree_.feature[node] != _tree.TREE_UNDEFINED:\nname_ = feature_names_[node]\nthreshold_ = tree_.threshold[node]\nthreshold_ = \"{:.{}f}\".format(threshold_, decimals)\nexport_text.report += right_child_fmt.format(indent, name_, threshold_)\nprint_tree_recurse(tree_.children_left[node], depth + 1)\n\nexport_text.report += left_child_fmt.format(indent, name_, threshold_)\nprint_tree_recurse(tree_.children_right[node], depth + 1)\nelse:\n_add_leaf(value, c, indent)\n         else:\n             subtree_depth = _compute_depth(tree_, node)\n             if subtree_depth == 1:\n_add_leaf(value, c, indent)\n             else:\ntrunc_report = \"truncated branch of depth {}\".format(subtree_depth)\nexport_text.report += truncation_fmt.format(indent, trunc_report)\n\ndef _compute_depth(tree, node):\ndef compute_depth_(current_node, current_depth, children_left, children_right, depths):\ndepths.append(current_depth)\nleft_ = children_left[current_node]\nright_ = children_right[current_node]\nif left_ != -1 and right_ != -1:\ncompute_depth_(left_, current_depth + 1, children_left, children_right, depths)\ncompute_depth_(right_, current_depth + 1, children_left, children_right, depths)\n\nd = []\ncompute_depth_(node, 1, tree.children_left, tree.children_right, d)\nreturn max(d)\n \n     print_tree_recurse(0, 1)\n     return export_text.report\n\n",
        "test_single_feature_export_text.py": "new file mode 100644\nindex 000000000..2a4f7cc88\n#!/usr/bin/env python\n\nimport sys\nimport traceback\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_text\nfrom sklearn.datasets import load_iris\n\ndef main():\nprint(\"[Step] Loading single-feature iris data.\")\nX, y = load_iris(return_X_y=True)\n# keep only the first feature\nX = X[:, 0].reshape(-1, 1)\n\nprint(\"[Step] Fitting DecisionTreeClassifier on single feature.\")\ntree = DecisionTreeClassifier()\ntree.fit(X, y)\n\nprint(\"[Step] Trying to call export_text(...) with feature_names=['sepal_length'].\")\ntry:\ntxt = export_text(tree, feature_names=['sepal_length'])\nprint(\"[PASSED] No IndexError thrown. Output:\")\nprint(txt)\nsys.exit(0)\nexcept Exception as e:\nprint(\"[FAILED] The call to export_text(...) raised an exception:\")\ntraceback.print_exc()\nsys.exit(1)\n\nif __name__ == \"__main__\":\nmain()\n"
    },
    "ground_truth_patch": {
        "sklearn/tree/export.py": "         value_fmt = \"{}{} value: {}\\n\"\n \n     if feature_names:\nfeature_names_ = [feature_names[i] if i != _tree.TREE_UNDEFINED\nelse None for i in tree_.feature]\n     else:\n         feature_names_ = [\"feature_{}\".format(i) for i in tree_.feature]\n \n"
    },
    "response": "{\"is_clone\": true, \"classification\": \"type-3\", \"reasoning\": \"These code samples are type-3 clones because they are syntactically similar but have added, modified, or removed statements. Specifically, while both samples deal with the construction of the 'feature_names_' variable, the second sample has a slight modification in the condition for the alternate case (if feature_names is None) where a different value is assigned, indicating a change in logic.\"}"
}