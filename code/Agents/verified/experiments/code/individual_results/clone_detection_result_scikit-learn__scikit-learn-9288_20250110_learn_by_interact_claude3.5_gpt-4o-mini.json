{
    "instance_id": "scikit-learn__scikit-learn-9288",
    "agent": "20250110_learn_by_interact_claude3.5",
    "agent_patch": {
        "reproduce_kmeans.py": "new file mode 100644\nindex 000000000..72a9eb7ff\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\n\n# Generate some data\nX, y = make_blobs(n_samples=10000, centers=10, n_features=2, random_state=2)\n\n# Run KMeans with various n_jobs values\nfor n_jobs in range(1, 5):\nkmeans = KMeans(n_clusters=10, random_state=2, n_jobs=n_jobs)\nkmeans.fit(X)\nprint(f'(n_jobs={n_jobs}) kmeans.inertia_ = {kmeans.inertia_}')\n",
        "sklearn/cluster/k_means_.py": "index b7fbdf7da..8ddefd320 100644\n     if effective_n_jobs(n_jobs) == 1:\n         # For a single thread, less memory is needed if we just store one set\n         # of the best results (as opposed to one set per run per thread).\nseeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\nfor seed in seeds:\n             # run a k-means once\n             labels, inertia, centers, n_iter_ = kmeans_single(\n                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,\n                 verbose=verbose, precompute_distances=precompute_distances,\n                 tol=tol, x_squared_norms=x_squared_norms,\nrandom_state=seed)\n             # determine if these results are the best so far\n             if best_inertia is None or inertia < best_inertia:\n                 best_labels = labels.copy()\n                 best_inertia = inertia\n                 best_n_iter = n_iter_\n     else:\n\n         # parallelisation of k-means runs\n         seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n         results = Parallel(n_jobs=n_jobs, verbose=0)(\n \n         X = self._check_test_data(X)\n         return self._labels_inertia_minibatch(X, sample_weight)[0]\n\n"
    },
    "ground_truth_patch": {
        "sklearn/cluster/k_means_.py": "     else:\n         raise ValueError(\"Algorithm must be 'auto', 'full' or 'elkan', got\"\n                          \" %s\" % str(algorithm))\n\nseeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n     if effective_n_jobs(n_jobs) == 1:\n         # For a single thread, less memory is needed if we just store one set\n         # of the best results (as opposed to one set per run per thread).\nfor seed in seeds:\n             # run a k-means once\n             labels, inertia, centers, n_iter_ = kmeans_single(\n                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,\n                 verbose=verbose, precompute_distances=precompute_distances,\n                 tol=tol, x_squared_norms=x_squared_norms,\nrandom_state=seed)\n             # determine if these results are the best so far\n             if best_inertia is None or inertia < best_inertia:\n                 best_labels = labels.copy()\n                 best_n_iter = n_iter_\n     else:\n         # parallelisation of k-means runs\n         results = Parallel(n_jobs=n_jobs, verbose=0)(\n             delayed(kmeans_single)(X, sample_weight, n_clusters,\n                                    max_iter=max_iter, init=init,\n"
    },
    "response": "{\"is_clone\": false, \"classification\": \"N/A\", \"reasoning\": \"These code samples are not clones because they are syntactically dissimilar and the content suggests they are part of different logic flows or contexts within the codebase. The first sample contains a complete KMeans operation with data generation, whereas the second sample focuses on an error handling section and condition checks for the algorithm type, indicating they serve distinct purposes in the code.\"}"
}