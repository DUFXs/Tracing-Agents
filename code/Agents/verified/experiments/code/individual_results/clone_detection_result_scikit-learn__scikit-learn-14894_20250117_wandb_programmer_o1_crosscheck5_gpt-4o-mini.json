{
    "instance_id": "scikit-learn__scikit-learn-14894",
    "agent": "20250117_wandb_programmer_o1_crosscheck5",
    "agent_patch": {
        "sklearn/svm/base.py": "index 64cebe837..be74d2468 100644\n \n         self._warn_from_fit_status()\n \ndef _sparse_fit(self, X, y, sample_weight, solver_type, kernel, random_seed):\n         X.data = np.asarray(X.data, dtype=np.float64, order='C')\n         X.sort_indices()\n\n         kernel_type = self._sparse_kernels.index(kernel)\n\n         libsvm_sparse.set_verbosity_wrap(self.verbose)\n\n         self.support_, self.support_vectors_, dual_coef_data, \\\n             self.intercept_, self._n_support, \\\n             self.probA_, self.probB_, self.fit_status_ = \\\n                 sample_weight, self.nu, self.cache_size, self.epsilon,\n                 int(self.shrinking), int(self.probability), self.max_iter,\n                 random_seed)\n\n         self._warn_from_fit_status()\n\n         if hasattr(self, \"classes_\"):\n             n_class = len(self.classes_) - 1\n         else:  # regression\n             n_class = 1\n         n_SV = self.support_vectors_.shape[0]\n\n# Fix: if there are zero support vectors, avoid creating array with 0 step\nif n_SV == 0:\nself.dual_coef_ = sp.csr_matrix((n_class, 0), dtype=np.float64)\nreturn\n\n         dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n         dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n                                      dual_coef_indices.size / n_class)\n         self.dual_coef_ = sp.csr_matrix(\n             (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n             (n_class, n_SV))\n\n \n     def predict(self, X):\n         \"\"\"Perform regression on samples in X.\n",
        "test_zero_division_bug.py": "new file mode 100644\nindex 000000000..f1d62e17d\nimport sys\nimport numpy as np\nimport scipy.sparse\nfrom sklearn.svm import SVR\n\nprint(\"Beginning test_zero_division_bug...\")\n\nx_train = np.array([\n[0, 1, 0, 0],\n[0, 0, 0, 1],\n[0, 0, 1, 0],\n[0, 0, 0, 1]], dtype=float)\ny_train = np.array([0.04, 0.04, 0.10, 0.16], dtype=float)\n\nmodel = SVR(C=316.227766017, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\ngamma=1.0, kernel='linear', max_iter=15000,\nshrinking=True, tol=0.001, verbose=False)\n\nprint(\"Fitting on dense matrix. Expect no error...\")\nmodel.fit(x_train, y_train)\nprint(\"Dense fit done successfully.\")\n\nprint(\"Converting x_train to sparse...\")\nx_train_sparse = scipy.sparse.csr_matrix(x_train)\n\nprint(\"Fitting on sparse matrix. Expect ZeroDivisionError on HEAD if bug persists.\")\ntry:\nmodel.fit(x_train_sparse, y_train)\nprint(\"No ZeroDivisionError => bug is fixed => exiting w/ code 0.\")\nsys.exit(0)\nexcept ZeroDivisionError:\nprint(\"ZeroDivisionError => bug present => exiting w/ code 1.\")\nsys.exit(1)\nexcept Exception as e:\nprint(f\"Unexpected exception => {str(e)} => exiting w/ code 2.\")\nsys.exit(2)\n"
    },
    "ground_truth_patch": {
        "sklearn/svm/base.py": "         n_SV = self.support_vectors_.shape[0]\n \n         dual_coef_indices = np.tile(np.arange(n_SV), n_class)\nif not n_SV:\nself.dual_coef_ = sp.csr_matrix([])\nelse:\ndual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\ndual_coef_indices.size / n_class)\nself.dual_coef_ = sp.csr_matrix(\n(dual_coef_data, dual_coef_indices, dual_coef_indptr),\n(n_class, n_SV))\n \n     def predict(self, X):\n         \"\"\"Perform regression on samples in X.\n"
    },
    "response": "{\"is_clone\": true, \"classification\": \"type-3\", \"reasoning\": \"These code samples are type-3 clones because they are syntactically similar but include added, modified, or removed statements. The second sample simplifies the logic that checks the number of support vectors with a change in the check from `if n_SV == 0:` to `if not n_SV:` and also modifies how it initializes `self.dual_coef_`. Thus, while they perform similar functions, the implementations are expressed with slight variations.\"}"
}