{
    "instance_id": "scikit-learn__scikit-learn-25931",
    "agent": "20250110_learn_by_interact_claude3.5",
    "agent_patch": {
        "reproduce.py": "new file mode 100644\nindex 000000000..bd19934dd\nfrom sklearn.ensemble import IsolationForest\nimport pandas as pd\nimport numpy as np\n\n# Test case 1: Original case\nX1 = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\nclf1 = IsolationForest(random_state=0, contamination=0.05).fit(X1)\n\n# Test case 2: Multiple numeric features\nX2 = pd.DataFrame({\n\"float\": [-1.1, 0.3, 0.5, 100],\n\"int\": [1, 2, 3, 4],\n\"int64\": pd.Series([1, 2, 3, 4], dtype=\"Int64\")  # pandas nullable integer\n})\nclf2 = IsolationForest(random_state=0, contamination=0.25).fit(X2)\n\n# Test case 3: contamination=\"auto\"\nX3 = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\nclf3 = IsolationForest(random_state=0, contamination=\"auto\").fit(X3)\n\nprint(\"All test cases completed without warnings!\")\n\n",
        "sklearn/ensemble/_iforest.py": "index 4d6c1c3f0..88c607093 100644\n             Fitted estimator.\n         \"\"\"\n         self._validate_params()\n# Store original input for offset computation when contamination != \"auto\"\nself._fit_X = X\n         X = self._validate_data(X, accept_sparse=[\"csc\"], dtype=tree_dtype)\n         if issparse(X):\n             # Pre-sort indices to avoid that each individual tree of the\n             self.offset_ = -0.5\n             return self\n \n# else, define offset_ wrt contamination parameter using original input\nself.offset_ = np.percentile(self.score_samples(self._fit_X), 100.0 * self.contamination)\ndel self._fit_X  # Remove reference to input data\n         return self\n \n\n     def predict(self, X):\n         \"\"\"\n         Predict if a particular sample is an outlier or not.\n     )\n \n     return average_path_length.reshape(n_samples_leaf_shape)\n\n"
    },
    "ground_truth_patch": {
        "sklearn/ensemble/_iforest.py": "             self.offset_ = -0.5\n             return self\n \n# Else, define offset_ wrt contamination parameter\n# To avoid performing input validation a second time we call\n# _score_samples rather than score_samples\nself.offset_ = np.percentile(self._score_samples(X), 100.0 * self.contamination)\n \n         return self\n \n             The anomaly score of the input samples.\n             The lower, the more abnormal.\n         \"\"\"\n         # Check data\n         X = self._validate_data(X, accept_sparse=\"csr\", dtype=np.float32, reset=False)\n \nreturn self._score_samples(X)\n\ndef _score_samples(self, X):\n\"\"\"Private version of score_samples without input validation.\n\nInput validation would remove feature names, so we disable it.\n\"\"\"\n# Code structure from ForestClassifier/predict_proba\n\ncheck_is_fitted(self)\n\n# Take the opposite of the scores as bigger is better (here less abnormal)\n         return -self._compute_chunked_score_samples(X)\n \n     def _compute_chunked_score_samples(self, X):\n"
    },
    "response": "{\"is_clone\": true, \"classification\": \"type-3\", \"reasoning\": \"These code samples are type-3 clones because they exhibit syntactical similarity but contain added, modified, or removed statements. The second sample modifies how `self.offset_` is calculated and includes additional comments and the definition of a `_score_samples` method, suggesting structural changes beyond simple identifier renaming or whitespace variations.\"}"
}