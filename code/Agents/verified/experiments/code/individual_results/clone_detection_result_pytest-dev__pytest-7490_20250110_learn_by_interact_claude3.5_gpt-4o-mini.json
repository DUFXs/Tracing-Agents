{
    "instance_id": "pytest-dev__pytest-7490",
    "agent": "20250110_learn_by_interact_claude3.5",
    "agent_patch": {
        "src/_pytest/skipping.py": "index 335e10996..fc5aacc86 100644\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n# Re-evaluate xfail marks during the call phase to catch dynamically added markers\nxfailed = item._store[xfailed_key] = evaluate_xfail_marks(item) if rep.when == \"call\" else item._store.get(xfailed_key, None)\n\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n \n\n     if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         elif report.passed:\n             return \"xpassed\", \"X\", \"XPASS\"\n     return None\n\n\n\ndiff --git \"a/src/_pytest/skipping.py\\\"\" \"b/src/_pytest/skipping.py\\\"\"\nnew file mode 100644\nindex 000000000..cce6d9198\n@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]):\noutcome = yield\nrep = outcome.get_result()\nxfailed = item._store[xfailed_key] = evaluate_xfail_marks(item) if rep.when == \"call\" else item._store.get(xfailed_key, None)\n"
    },
    "ground_truth_patch": {
        "src/_pytest/skipping.py": " \n @hookimpl(tryfirst=True)\n def pytest_runtest_setup(item: Item) -> None:\n     skipped = evaluate_skip_marks(item)\nitem._store[skipped_by_mark_key] = skipped is not None\n     if skipped:\n         skip(skipped.reason)\n \nitem._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\nif xfailed and not item.config.option.runxfail and not xfailed.run:\nxfail(\"[NOTRUN] \" + xfailed.reason)\n \n \n @hookimpl(hookwrapper=True)\n     if xfailed is None:\n         item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n \nif xfailed and not item.config.option.runxfail and not xfailed.run:\nxfail(\"[NOTRUN] \" + xfailed.reason)\n \n     yield\n \n# The test run may have added an xfail mark dynamically.\nxfailed = item._store.get(xfailed_key, None)\nif xfailed is None:\nitem._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n\n \n @hookimpl(hookwrapper=True)\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n"
    },
    "response": "{\"is_clone\": true, \"classification\": \"type-3\", \"reasoning\": \"These code samples are type-3 clones because they exhibit syntactic similarities with added, modified, or removed statements. Both samples define the function `pytest_runtest_makereport` and have similarities in the logic surrounding handling of `xfailed`, but they also contain significant differences in structure and additional logic, such as the treatment of `skipped` tests. The overall function names and purposes are similar, but they involve modified content and surrounding logic.\"}"
}